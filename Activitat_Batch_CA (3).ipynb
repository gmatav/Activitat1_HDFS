{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"GUILLEM MATA VALLIGNY\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b73bb7a62634f8b1c08dd7e4e734c08e",
     "grade": false,
     "grade_id": "cell-69f82fe8cdafb296",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# ![Logotip de Spark](http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png)\n",
    "\n",
    "# Activitat BATCH\n",
    "\n",
    "## Sistema de fitxers HDFS i extracció de coneixement de fonts de dades heterogènies mitjançant RDDs\n",
    "\n",
    "En aquesta pràctica començarem amb una breu introducció a HDFS (Hadoop Distributed File System), per entendre com s'emmagatzema i distribueix la informació. Després, ens endinsarem en Spark RDDs i  Spark SQL per processar grans volums de dades de manera eficient. Per finalitzar, treballarem amb dades relacionals i la seva gestió en entorns distribuïts.\n",
    "\n",
    "### Puntuació de l'activitat:\n",
    "- **Exercici 1**: Gestió i anàlisi de dades en HDFS *(0.5 punts)*\n",
    "- **Exercici 2**: Manipulació de RDDs en PySpark *(1.25 punts)*\n",
    "- **Exercici 3**: Anàlisi de Dades de Tweets en PySpark *(1.25 punts)*\n",
    "- **Exercici 4**: Optimització de Càlculs amb Persistència *(0.25 punts)*\n",
    "- **Exercici 5**: Anàlisi de Tweets mitjançant DataFrames i consultes SQL *(2 punts)*\n",
    "- **Exercici 6**: Anàlisi de Tweets Geolocalitzats *(1.5 punts)*\n",
    "- **Exercici 7**: Anàlisi del Patró d'Activitat Horària a Twitter *(1 punts)*\n",
    "- **Exercici 8**: Anàlisi de la Relació entre Tweets i Diputats per Província *(0.75 punts)*\n",
    "- **Exercici 9**: Anàlisi d'Interaccions de Retweets i Graus d'Usuari *(0.75 punts)*\n",
    "- **Exercici 10**: Distribució del Grau de Sortida en una Xarxa de Retweets *(0.75 punts)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2657540ca46e5f992d5773116abc9be4",
     "grade": false,
     "grade_id": "cell-22bd70ec4e955130",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# **HDFS (Hadoop Distributed File System)**\n",
    "\n",
    "<img src=\"https://hadoop.apache.org/docs/r1.2.1/images/hadoop-logo.jpg\">\n",
    "\n",
    "**HDFS (Hadoop Distributed File System)** és una part essencial de l'ecosistema Big Data d'Apache Hadoop. HDFS està dissenyat per emmagatzemar i gestionar grans volums de dades distribuïdes en diversos nodes d'un clúster, proporcionant alta tolerància a fallades i escalabilitat. En aquest primer exercici, interactuarem amb HDFS mitjançant la línia de comandes dins de l'entorn de **JupyterLab**, el que ens permetrà familiaritzar-nos amb les operacions bàsiques d'aquest sistema de fitxers distribuït.\n",
    "\n",
    "Per començar, és necessari obrir un terminal des de **JupyterLab**. Un cop obert, podem enviar comandes al sistema de fitxers HDFS, que són molt similars a les comandes de bash en entorns Linux. Algunes de les comandes d'HDFS que executarem començaran amb `hdfs dfs`, seguides de l'operació que desitgem realitzar. Per exemple, si volem llistar els fitxers i directoris en el directori arrel d'HDFS, utilitzarem la comanda ls de la següent manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9961bedbeb8070d357ae2754a5a89fc0",
     "grade": false,
     "grade_id": "cell-063a70159c8ff11f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 items\r\n",
      "drwxr-xr-x   - asolerib   supergroup          0 2020-01-16 22:12 /CFCC\r\n",
      "drwxrwxr-x   - egilbl     students            0 2024-10-01 17:24 /aula_B0.476\r\n",
      "drwxr-xr-x   - asolerib   supergroup          0 2019-10-28 11:09 /aula_B2.585\r\n",
      "drwxr-xr-x   - asolerib   supergroup          0 2019-09-25 22:10 /aula_M2.858\r\n",
      "drwxr-xr-x   - hbase      hbase               0 2024-10-22 12:25 /hbase\r\n",
      "drwxr-xr-x   - aperezgari supergroup          0 2021-08-05 12:58 /home\r\n",
      "drwxr-xr-x   - joant      supergroup          0 2023-12-10 20:28 /path\r\n",
      "drwxrwxr-x   - solr       solr                0 2019-07-23 15:49 /solr\r\n",
      "drwxrwxrwt   - hdfs       supergroup          0 2024-10-20 10:04 /tmp\r\n",
      "drwxrwxr-x   - hdfs       supergroup          0 2024-10-22 12:47 /user\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "717858353afc0c954f4493cf23cdb6a8",
     "grade": false,
     "grade_id": "cell-464a41261fdc6d72",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "És important que totes les comandes s'executin correctament en l'entorn **JupyterLab** per obtenir els resultats desitjats.\n",
    "\n",
    "Per consultar la documentació completa de les comandes disponibles en HDFS, pots accedir a la guia oficial en el següent enllaç: [HDFS Command Guide](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html)\n",
    "\n",
    "Al llarg d'aquest exercici, utilitzarem algunes de les comandes més comunes d'HDFS per realitzar operacions com la creació de directoris, la càrrega i descàrrega d'arxius, i la gestió de permisos, entre altres. A mesura que avancem, et familiaritzaràs amb l'estructura d'HDFS i com aprofitar les seves funcionalitats en entorns Big Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b5ead01c68dbd8653c4acff8fb6a0ee1",
     "grade": false,
     "grade_id": "cell-2ae82872afbd0db8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### **Exercici 1**: Gestió i anàlisi de dades en HDFS (*0.5 punts*)\n",
    "\n",
    "En aquest exercici, treballaràs amb un fitxer de dades de vendes anomenat `ventas_globales.txt`, emmagatzemat a la següent ruta `/aula_M2.858/data/ventas_globales.txt`. El teu objectiu és realitzar una sèrie de tasques d'anàlisi, gestió i verificació d'integritat de les dades. A continuació es detallen les tasques a realitzar.\n",
    "\n",
    "- Necessites obtenir informació sobre la mida del fitxer `ventas_globales.txt`, i també hauràs de realitzar una anàlisi preliminar del contingut del fitxer sense descarregar-lo completament.\n",
    "\n",
    "- A continuació, hauràs de descarregar una còpia del fitxer `ventas_globales.txt` al teu sistema local. És important verificar que el fitxer en HDFS no presenta problemes d'integritat ni blocs corruptes. Assegura't de comprovar l'estat del fitxer. Un cop hagis verificat que el fitxer està correcte i no presenta problemes d'integritat, hauràs de tornar a pujar-lo dins de la carpeta `procesado` que has de crear a la ruta `/user/[el_teu_usuari]/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa9ad9ce3e1fce78156db6637c43a6fd",
     "grade": true,
     "grade_id": "cell-2fffed3adbc9a755",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1330  3990  /aula_M2.858/data/ventas_globales.txt\n",
      "\n",
      "\n",
      "ID_Venta;Producto;Cantidad;Precio\n",
      "1;Smartphone;5;300.00\n",
      "2;Laptop;3;800.00\n",
      "3;Tablet;2;250.00\n",
      "4;Auriculares;7;50.00\n",
      "5;Reloj inteligente;1;150.00\n",
      "6;Televisor;4;600.00\n",
      "7;Cámara;8;400.00\n",
      "8;Altavoz Bluetooth;6;75.00\n",
      "9;Monitor;2;200.00\n",
      "10;Impresora;10;120.00\n",
      "11;Smartphone;4;300.00\n",
      "12;Laptop;8;800.00\n",
      "13;Tablet;6;250.00\n",
      "14;Auriculares;3;50.00\n",
      "15;Reloj inteligente;2;150.00\n",
      "16;Televisor;5;600.00\n",
      "17;Cámara;7;400.00\n",
      "18;Altavoz Bluetooth;1;75.00\n",
      "19;Monitor;3;200.00\n",
      "\n",
      "\n",
      "get: `ventas_globales.txt': File exists\n",
      "Connecting to namenode via http://eimtcld.uoc.edu:9870/fsck?ugi=gmatav&path=%2Faula_M2.858%2Fdata%2Fventas_globales.txt\n",
      "FSCK started by gmatav (auth:SIMPLE) from /213.73.35.119 for path /aula_M2.858/data/ventas_globales.txt at Wed Oct 23 19:53:53 CEST 2024\n",
      "\n",
      "Status: HEALTHY\n",
      " Number of data-nodes:\t3\n",
      " Number of racks:\t\t1\n",
      " Total dirs:\t\t\t0\n",
      " Total symlinks:\t\t0\n",
      "\n",
      "Replicated Blocks:\n",
      " Total size:\t1330 B\n",
      " Total files:\t1\n",
      " Total blocks (validated):\t1 (avg. block size 1330 B)\n",
      " Minimally replicated blocks:\t1 (100.0 %)\n",
      " Over-replicated blocks:\t0 (0.0 %)\n",
      " Under-replicated blocks:\t0 (0.0 %)\n",
      " Mis-replicated blocks:\t\t0 (0.0 %)\n",
      " Default replication factor:\t3\n",
      " Average block replication:\t3.0\n",
      " Missing blocks:\t\t0\n",
      " Corrupt blocks:\t\t0\n",
      " Missing replicas:\t\t0 (0.0 %)\n",
      " Blocks queued for replication:\t0\n",
      "\n",
      "Erasure Coded Block Groups:\n",
      " Total size:\t0 B\n",
      " Total files:\t0\n",
      " Total block groups (validated):\t0\n",
      " Minimally erasure-coded block groups:\t0\n",
      " Over-erasure-coded block groups:\t0\n",
      " Under-erasure-coded block groups:\t0\n",
      " Unsatisfactory placement block groups:\t0\n",
      " Average block group size:\t0.0\n",
      " Missing block groups:\t\t0\n",
      " Corrupt block groups:\t\t0\n",
      " Missing internal blocks:\t0\n",
      " Blocks queued for replication:\t0\n",
      "FSCK ended at Wed Oct 23 19:53:53 CEST 2024 in 0 milliseconds\n",
      "\n",
      "\n",
      "The filesystem under path '/aula_M2.858/data/ventas_globales.txt' is HEALTHY\n",
      "put: `/user/gmatav/procesado/ventas_globales.txt': File exists\n"
     ]
    }
   ],
   "source": [
    "#  obtenir informació sobre la mida del fitxer\n",
    "!hadoop fs -du -s /aula_M2.858/data/ventas_globales.txt\n",
    "print(\"\\n\") \n",
    "\n",
    "#  realitzar una anàlisi preliminar del contingut del fitxer \n",
    "!hadoop fs -text /aula_M2.858/data/ventas_globales.txt | head -n 20\n",
    "print(\"\\n\") \n",
    "\n",
    "#  descarregar una còpia del fitxer ventas_globales.txt al teu sistema local\n",
    "!hadoop fs -get /aula_M2.858/data/ventas_globales.txt .\n",
    "\n",
    "#verificar que el fitxer en HDFS no presenta problemes d'integritat ni blocs corruptes\n",
    "!hdfs fsck /aula_M2.858/data/ventas_globales.txt\n",
    "\n",
    "\n",
    "# tornar a pujar-lo dins de la carpeta 'procesado'\n",
    "!hadoop fs -put ventas_globales.txt /user/gmatav/procesado\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2cfe0dd7d2ac309e3b414008e0d52dd5",
     "grade": false,
     "grade_id": "cell-808506bd1cf34534",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# **Apache Spark RDDs (Resilient Distributed Datasets)**\n",
    "\n",
    "En el marc del processament de grans volums de dades amb Apache Spark, els RDDs, o Resilient Distributed Datasets, juguen un paper fonamental. Un RDD és una col·lecció d'elements que es distribueixen a través d'un clúster de nodes i sobre la qual es poden aplicar operacions que s'executen en paral·lel.\n",
    "\n",
    "Recordem les seves característiques:\n",
    "\n",
    "- Immutabilitat: Un cop es crea un RDD, no es pot modificar. En lloc d'això, qualsevol operació que modifiqui les dades generarà un nou RDD.\n",
    "\n",
    "- Distribució: Els RDDs estan repartits entre els diferents nodes del clúster, permetent un processament paral·lel eficient.\n",
    "\n",
    "- Tolerància a Fallades: Els RDDs són resistents a fallades. En cas que un node falli, Spark pot reconstruir les dades perdudes a partir de les dades originals i les operacions realitzades.\n",
    "\n",
    "Aquesta estructura permet un processament eficient i escalable de dades, cosa que és essencial per treballar amb grans volums d'informació en entorns de clúster.\n",
    "\n",
    "A continuació es mostra el codi que heu d'executar per configurar el vostre entorn de Spark.\n",
    "\n",
    "> Com a referència a tots els mètodes que es requereixen per implementar aquesta pràctica podeu consultar:\n",
    "> * [API Python de Spark](https://archive.apache.org/dist/spark/docs/2.4.0/api/python/index.html)\n",
    "\n",
    "### Configuració de l'entorn python + spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a7c39355a24728f035b179efa8a2319",
     "grade": false,
     "grade_id": "cell-94e40aa6abb9fc31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x7fc1c60ceb38>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.setMaster(\"local[1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0-cdh6.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Introduïu el nom de l'app ActivitatRDDs_ seguit del vostre nom d'usuari\n",
    "conf.setAppName(\"ActivitatRDDs_gmatav\")\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "sc.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd136619d78df6eb980050ff1de70825",
     "grade": false,
     "grade_id": "cell-9f46f77f8b9ce131",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### **Exercici 2**: Manipulació de RDDs en PySpark (*1.25 punts*)\n",
    "\n",
    "En aquest exercici, et proporcionem dues llistes de números en les quals realitzaràs diverses operacions sobre elles utilitzant RDDs en PySpark. La solució i l'enfocament queden al teu criteri.\n",
    "Context:\n",
    "\n",
    "Tens dos conjunts de números:\n",
    "- Conjunt 1: Números de l'1 al 20.\n",
    "- Conjunt 2: Números del 10 al 30.\n",
    "\n",
    "Descripció:\n",
    "\n",
    "- Has de crear RDDs a partir d'aquests conjunts de números.\n",
    "\n",
    "- Has de transformar el primer RDD per associar cada número amb el seu quadrat. Després, filtra les parelles en què el quadrat és superior a 50. A aquest RDD filtrat l'has d'anomenar `filtrados_rdd`.\n",
    "\n",
    "- Agrupa les dades filtrades en funció de si els números originals són parells o senars. Després, calcula la suma dels quadrats per a cada grup. A aquest RDD de la suma dels quadrats, l'has d'anomenar `suma_cuadrados_rdd`.\n",
    "\n",
    "- Realitza una unió i intersecció entre els dos RDDs inicials dels conjunts de llistes, hauràs d'anomenar-los `union_rdd` i `interseccion_rdd` respectivament.\n",
    "\n",
    "- Imprimeix els resultats de cadascuna de les operacions realitzades utilitzant el mètode collect()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "564e8b1cacc0e1eac5bf9bfb9fccc6eb",
     "grade": false,
     "grade_id": "cell-314f0ca23b33a2f2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associar cada número amb el seu quadrat: [(1, 1), (2, 4), (3, 9), (4, 16), (5, 25), (6, 36), (7, 49), (8, 64), (9, 81), (10, 100), (11, 121), (12, 144), (13, 169), (14, 196), (15, 225), (16, 256), (17, 289), (18, 324), (19, 361), (20, 400)] \n",
      "\n",
      "Filtrar les parelles amb el quadrat superior a 50: [(8, 64), (9, 81), (10, 100), (11, 121), (12, 144), (13, 169), (14, 196), (15, 225), (16, 256), (17, 289), (18, 324), (19, 361), (20, 400)] \n",
      "\n",
      "Agrupar les dades filtrades si els números originals són parells: [(9, 81), (11, 121), (13, 169), (15, 225), (17, 289), (19, 361)] \n",
      "\n",
      "Agrupar les dades filtrades si els números originals són senars: [(8, 64), (10, 100), (12, 144), (14, 196), (16, 256), (18, 324), (20, 400)] \n",
      "\n",
      "La suma dels quadrats del grup dels senars: 1484 \n",
      "\n",
      "La suma dels quadrats del grup dels parells: 1246 \n",
      "\n",
      "RDD de la suma dels quadrats: [('parells', 1246), ('senars', 1484)] \n",
      "\n",
      "Unió entre els dos RDD inicials: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30] \n",
      "\n",
      "Intersecció entre els dos RDD inicials: [10, 12, 14, 16, 18, 20, 11, 13, 15, 17, 19] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Conjunts de números\n",
    "conjunt1 = list(range(1, 21))\n",
    "conjunt2 = list(range(10, 31))\n",
    "\n",
    "#  crear RDDs a partir d'aquests conjunts de números.\n",
    "rdd1 = sc.parallelize(conjunt1)\n",
    "rdd2 = sc.parallelize(conjunt2)\n",
    "\n",
    "# transformar el primer RDD per associar cada número amb el seu quadrat.\n",
    "quadrats_rdd = rdd1.map(lambda x: (x, x ** 2))\n",
    "\n",
    "# Després, es filtra les parelles en què el quadrat és superior a 50\n",
    "filtrados_rdd = quadrats_rdd.filter(lambda x: x[1] > 50)\n",
    "\n",
    "# Agrupar les dades filtrades en funció de si els números originals són parells o senars\n",
    "parells = filtrados_rdd.filter(lambda x: (x[0]%2 != 0))\n",
    "senars = filtrados_rdd.filter(lambda x: (x[0]%2 == 0))     \n",
    "\n",
    "# calcula la suma dels quadrats per a cada grup\n",
    "suma_senars = senars.map(lambda x: x[1]).sum()\n",
    "suma_parells = parells.map(lambda x: x[1]).sum()\n",
    "\n",
    "# RDD de la suma dels quadrats,\n",
    "suma_cuadrados_rdd = sc.parallelize([(\"parells\", suma_parells), (\"senars\", suma_senars)])\n",
    "\n",
    "                    \n",
    "# Realitza una unió i intersecció entre els dos RDDs inicials dels conjunts de llistes\n",
    "union_rdd = rdd1.union(rdd2)\n",
    "interseccion_rdd = rdd1.intersection(rdd2)\n",
    "\n",
    "\n",
    "# Imprimeix els resultats de cadascuna de les operacions realitzades utilitzant el mètode collect().\n",
    "print(\"Associar cada número amb el seu quadrat:\", quadrats_rdd.collect(), \"\\n\")\n",
    "print(\"Filtrar les parelles amb el quadrat superior a 50:\", filtrados_rdd.collect(), \"\\n\")\n",
    "print(\"Agrupar les dades filtrades si els números originals són parells:\", parells.collect(), \"\\n\")\n",
    "print(\"Agrupar les dades filtrades si els números originals són senars:\", senars.collect(), \"\\n\")\n",
    "print(\"La suma dels quadrats del grup dels senars:\", suma_senars, \"\\n\")\n",
    "print(\"La suma dels quadrats del grup dels parells:\", suma_parells, \"\\n\")\n",
    "print(\"RDD de la suma dels quadrats:\", suma_cuadrados_rdd.collect(), \"\\n\")\n",
    "print(\"Unió entre els dos RDD inicials:\", union_rdd.collect(), \"\\n\")\n",
    "print(\"Intersecció entre els dos RDD inicials:\", interseccion_rdd.collect(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4819a1c09a5625d4019fa8b58248bb4c",
     "grade": true,
     "grade_id": "cell-bd7fd26bac3713f9",
     "locked": true,
     "points": 1.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "\"Solution\""
    ]
   },
   "outputs": [],
   "source": [
    "# DO NOT USE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2867018a7fdb00eb59baa8d58dc163fc",
     "grade": false,
     "grade_id": "cell-de380caf2d1be8bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### **Exercici 3**: Anàlisi de Dades de Tweets en PySpark (*1.25 punts*)\n",
    "\n",
    "En aquest exercici, treballaràs amb un fitxer JSON anomenat `tweets_sample.json` que es troba a la ruta `/aula_M2.858/data/tweets_sample.json`. Aquest fitxer conté dades de tweets i mètriques relacionades. Hauràs d'utilitzar PySpark per realitzar una anàlisi de les dades. L'estructura del fitxer JSON inclou informació com el nombre de retweets, likes, seguidors, i més. No obstant això, per a aquest exercici, et centraràs en processar i analitzar el contingut textual dels tweets.\n",
    "\n",
    "- Carrega el fitxer JSON en un RDD utilitzant el mètode `textFile()`. Examina l'estructura de les dades per identificar com extreure el contingut rellevant.\n",
    "\n",
    "- Extreu el camp tweets de cadascun dels tweets. Defineix i aplica una funció per netejar el text. Aquesta funció ha d'eliminar la puntuació, convertir el text a minúscules i assegurar que hi hagi un sol espai entre les paraules.\n",
    "\n",
    "- Divideix el text en paraules i filtra les paraules per quedar-te amb aquelles que tinguin més de 3 caràcters. Després, realitza un recompte de paraules diferents que has d'anomenar `palabras_distintas_rdd`.\n",
    "\n",
    "- Finalment, troba les 5 paraules més freqüents que contenen la lletra 'z', a aquest RDD l'has d'anomenar `top_palabras_con_z`.\n",
    "\n",
    "- Imprimeix els resultats de cadascuna de les operacions realitzades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f13f8026a21d9a4fd22978e174f42d34",
     "grade": false,
     "grade_id": "cell-eaafb37f86841f7f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Es mostra el contingut de les dades: \n",
      "\n",
      "{\"tweet_id\": 1, \"user\": \"usuario1\", \"followers\": 150, \"retweets\": 5, \"likes\": 10, \"tweet\": \"¡Hola mundo! Este es un tweet de prueba para ver cómo funciona. #prueba #mundo\"}\n",
      "{\"tweet_id\": 2, \"user\": \"usuario2\", \"followers\": 300, \"retweets\": 2, \"likes\": 7, \"tweet\": \"Los datos son el nuevo petróleo. Analiza, visualiza y actúa. #data #análisis\"}\n",
      "{\"tweet_id\": 3, \"user\": \"usuario3\", \"followers\": 500, \"retweets\": 15, \"likes\": 20, \"tweet\": \"Un día productivo en la oficina. ¿Alguna vez has tenido un día así? #productividad\"}\n",
      "{\"tweet_id\": 4, \"user\": \"usuario4\", \"followers\": 250, \"retweets\": 10, \"likes\": 5, \"tweet\": \"¿Sabías que Python es uno de los lenguajes de programación más utilizados? #Python #programación\"}\n",
      "{\"tweet_id\": 5, \"user\": \"usuario5\", \"followers\": 100, \"retweets\": 1, \"likes\": 3, \"tweet\": \"La programación puede ser divertida y emocionante. ¡No te rindas! #programación\"}\n",
      "{\"tweet_id\": 6, \"user\": \"usuario6\", \"followers\": 400, \"retweets\": 0, \"likes\": 2, \"tweet\": \"Zorro: un animal ágil y rápido. #naturaleza #zorro\"}\n",
      "{\"tweet_id\": 7, \"user\": \"usuario7\", \"followers\": 600, \"retweets\": 12, \"likes\": 22, \"tweet\": \"La zona de confort es un lugar agradable, pero nada crece allí. #motivación\"}\n",
      "{\"tweet_id\": 8, \"user\": \"usuario8\", \"followers\": 50, \"retweets\": 1, \"likes\": 1, \"tweet\": \"Zambullirse en nuevas experiencias es crucial. ¡Atrévete a salir! #experiencias\"}\n",
      "{\"tweet_id\": 9, \"user\": \"usuario9\", \"followers\": 350, \"retweets\": 7, \"likes\": 15, \"tweet\": \"Zapatillas nuevas para correr. ¡Listo para la maratón! #fitness\"}\n",
      "{\"tweet_id\": 10, \"user\": \"usuario10\", \"followers\": 80, \"retweets\": 3, \"likes\": 5, \"tweet\": \"Disfrutando de un buen libro. Siempre es un placer. #lectura\"}\n",
      "\n",
      "\n",
      "Tweets extrets i netejats: PythonRDD[132] at RDD at PythonRDD.scala:53 \n",
      "\n",
      "hola mundo este es un tweet de prueba para ver cómo funciona prueba mundo\n",
      "los datos son el nuevo petróleo analiza visualiza y actúa data análisis\n",
      "un día productivo en la oficina ¿alguna vez has tenido un día así productividad\n",
      "¿sabías que python es uno de los lenguajes de programación más utilizados python programación\n",
      "la programación puede ser divertida y emocionante no te rindas programación\n",
      "zorro un animal ágil y rápido naturaleza zorro\n",
      "la zona de confort es un lugar agradable pero nada crece allí motivación\n",
      "zambullirse en nuevas experiencias es crucial atrévete a salir experiencias\n",
      "zapatillas nuevas para correr listo para la maratón fitness\n",
      "disfrutando de un buen libro siempre es un placer lectura\n",
      "\n",
      "\n",
      "Text dividit en paraules: PythonRDD[134] at RDD at PythonRDD.scala:53 \n",
      "\n",
      "hola\n",
      "mundo\n",
      "este\n",
      "es\n",
      "un\n",
      "tweet\n",
      "de\n",
      "prueba\n",
      "para\n",
      "ver\n",
      "\n",
      "\n",
      "Recompte de paraules diferents que tinguin més de 3 caràcters: 61 \n",
      "\n",
      "5 paraules més freqüents que contenen la lletra 'z': [('zorro', 2), ('utilizados', 1), ('vez', 1), ('zapatillas', 1), ('visualiza', 1)]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# Carregar el fitzer JSON en un RDD\n",
    "text_path = \"/aula_M2.858/data/tweets_sample.json\"\n",
    "RDD_tweets = sc.textFile(text_path)\n",
    "\n",
    "# Examinar l'estructura de les dades i mostra per pantalla\n",
    "print(\"Es mostra el contingut de les dades:\",\"\\n\")\n",
    "for line in RDD_tweets.take(10):\n",
    "    print (line)\n",
    "    \n",
    "# Extreu el camp tweets de cadascun dels tweets\n",
    "tweets = RDD_tweets.map(lambda x: json.loads(x)['tweet'])\n",
    "\n",
    "# Defineix i aplica una funció per netejar el text\n",
    "def netejar(x):\n",
    "    punc = '¡!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "    lowercased_str = x.lower()\n",
    "    for ch in punc:\n",
    "        lowercased_str = lowercased_str.replace(ch, '')\n",
    "    cleansed = re.sub(r'\\s+', ' ', lowercased_str).strip()\n",
    "    \n",
    "    return cleansed\n",
    "\n",
    "# Aplicar la funció de neteja al camp 'tweet'\n",
    "tweets_nets = tweets.map(netejar)\n",
    "print(\"\\n\")\n",
    "print(\"Tweets extrets i netejats:\", tweets_nets, \"\\n\")\n",
    "for tweet in tweets_nets.take(10):  # Mostra les primeres 10 tweets\n",
    "    print(tweet)\n",
    "    \n",
    "#Divideix el text en paraules \n",
    "paraules_rdd = tweets_nets.flatMap(lambda x: x.split())\n",
    "print(\"\\n\")\n",
    "print(\"Text dividit en paraules:\", paraules_rdd, \"\\n\")\n",
    "for paraula in paraules_rdd.take(10):  # Mostra les primeres 10 paraules\n",
    "    print(paraula)\n",
    "    \n",
    "# filtra les paraules per quedar-te amb aquelles que tinguin més de 3 caràcters\n",
    "mes_de_tres = paraules_rdd.filter(lambda paraula: len(paraula) > 3)\n",
    "\n",
    "#  recompte de paraules diferents\n",
    "palabras_distintas_rdd = mes_de_tres.distinct().count()\n",
    "print(\"\\n\")\n",
    "print(\"Recompte de paraules diferents que tinguin més de 3 caràcters:\", palabras_distintas_rdd, \"\\n\")\n",
    "\n",
    "# les 5 paraules més freqüents que contenen la lletra 'z'\n",
    "top_palabras_con_z =  paraules_rdd.filter(lambda paraula: 'z' in paraula).map(lambda paraula: (paraula, 1)).reduceByKey(lambda a, b: a + b).sortBy(lambda x: -x[1]).take(5)\n",
    "print(\"5 paraules més freqüents que contenen la lletra 'z':\", top_palabras_con_z)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "147a3fd5bd392b7593e9ddb6b7e4a830",
     "grade": true,
     "grade_id": "cell-ad5950094d75a2e5",
     "locked": true,
     "points": 1.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "hidden"
    ]
   },
   "outputs": [],
   "source": [
    "# DO NOT USE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "769e93f043f0440519235f2e01091ddb",
     "grade": false,
     "grade_id": "cell-cefc491088ccac0c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### **Exercici 4**: Optimització de Càlculs amb Persistència (*0.25 punts*)\n",
    "\n",
    "Per reduir els temps d'execució en Spark, és fonamental utilitzar la persistència d'un RDD mitjançant el mètode `persist()`. Aquesta tècnica és particularment útil quan es realitzen múltiples operacions repetides sobre un mateix RDD.\n",
    "\n",
    "Quan persisteixes un RDD, Spark emmagatzema les dades en memòria (o en disc, depenent del nivell de persistència, per veure més sobre els nivells de persistència aneu a la web [Persistència Spark](https://archive.apache.org/dist/spark/docs/2.4.0/rdd-programming-guide.html#rdd-persistence)) per evitar recomputacions cada vegada que es necessita realitzar una acció sobre el RDD. Això significa que cada node del clúster guarda en la seva memòria les particions del RDD que ha processat, permetent que les següents operacions sobre el RDD siguin molt més ràpides.\n",
    "\n",
    "**Mesura de Rendiment**\n",
    "\n",
    "Per mesurar la millora en els temps d'execució, podem utilitzar la funció màgica `%%time` en un entorn Jupyter Notebook, que permet observar:\n",
    "\n",
    "- Wall clock time: Temps total real que porta executar una tasca, incloent la CPU, el temps d'entrada/sortida (I/O), i les possibles comunicacions entre nodes en el clúster.\n",
    "\n",
    "- CPU time: Temps efectiu en què la CPU està ocupada executant la tasca, excloent altres latències com la d'entrada/sortida.\n",
    "\n",
    "En aquest exercici, s'explorarà l'ús de la persistència en RDDs (Resilient Distributed Datasets) utilitzant PySpark. L'objectiu és observar com la persistència afecta el rendiment de les operacions de transformació i acció sobre els RDDs.\n",
    "\n",
    "- Crea un RDD a partir d'una llista de números que va de l'1 al 10.000.\n",
    "\n",
    "- Filtra el RDD per obtenir només els números majors a 5.000 i emmagatzema aquest resultat en un nou RDD.\n",
    "\n",
    "- Aplica una transformació per duplicar els valors del RDD filtrat i guarda'l en un nou RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "88d1f94f61cf8091d75d76973b440b9a",
     "grade": true,
     "grade_id": "cell-20e79b00bce6a99d",
     "locked": false,
     "points": 0.04,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dcb36fe7ef37c6f431057e451a1fef3c",
     "grade": false,
     "grade_id": "cell-3cc02595e4869b7d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- Utilitza el mètode collect() per recuperar i mostrar els números majors a 5.000 i els seus dobles, i mesura el temps que triga en executar-se aquesta operació utilitzant la funció màgica `%%time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23b72a5343db9dadc5582c54a56ceaf3",
     "grade": true,
     "grade_id": "cell-dbd8ed0fbe6cb2e3",
     "locked": false,
     "points": 0.04,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "96fddafe122d2d06878b3f041f6e552f",
     "grade": false,
     "grade_id": "cell-d552f98ea8b2ccfc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- Aplica la persistència sobre el RDD de nombres majors a 5.000 per a que ele seu contingut es mantingui en memòria entre les operacions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aefdc6adb43c2eef8d0744aa4a981b66",
     "grade": true,
     "grade_id": "cell-b2f0d0dbfa3b2fc6",
     "locked": false,
     "points": 0.04,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2e0ec2fa5c64d1dd3cfdaef3a453b8ac",
     "grade": false,
     "grade_id": "cell-e317e144dfbc4476",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- Torna a executar el mètode collect() com abans. Compara aquest temps amb el temps de la primera execució. (Pots executar-lo diverses vegades i veure què passa amb el temps de processament.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "891aea65d397202a51e4e7f630fc50b2",
     "grade": true,
     "grade_id": "cell-bedf951e466e2a8f",
     "locked": false,
     "points": 0.04,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff285d3f0c0cf0fd3be4eac67302e089",
     "grade": false,
     "grade_id": "cell-6d7fc7daa908a284",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- Elimina la persistència de l'RDD utilitzant `unpersist()` per alliberar recursos i atura la sessió de Spark al final de l'exercici amb `sc.stop()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f59a0df333b77f9a1b5ae6d14d6ff7d5",
     "grade": true,
     "grade_id": "cell-758588781a39fc7c",
     "locked": false,
     "points": 0.04,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ceb336b1a70ce77de11f7c18a851e6a8",
     "grade": false,
     "grade_id": "cell-a26ae2c6d94330f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- Al finalitzar l'exercici, analitza i comenta els resultats obtinguts, explicant com la persistència va afectar el rendiment dels teus càlculs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0dbed1299cf2ee33d9803541c0a82438",
     "grade": true,
     "grade_id": "cell-8c4867c600d1589a",
     "locked": false,
     "points": 0.05,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "21e2804ca88620f852f18cd653794ace",
     "grade": false,
     "grade_id": "cell-8be99cc6aa71a595",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# **Apache Spark Dataframes**\n",
    "\n",
    "En aquesta part de la pràctica introduirem els elements que ofereix Spark per treballar amb estructures de dades. Veurem des d'estructures molt simples fins a estructures complexes, on els camps poden al seu torn tenir camps niats. En concret utilitzarem dades de Twitter capturades en el context de les eleccions generals a Espanya del 28 d'abril de 2019.\n",
    "\n",
    "### Configuració de l'entorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a701a660c946c6183d1ab080a4beeab8",
     "grade": false,
     "grade_id": "cell-1c9b92951b2b66ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a63019694978ebeccd777c939176501",
     "grade": false,
     "grade_id": "cell-fdb813eb32e1d141",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from math import floor\n",
    "from pyspark import SparkConf, SparkContext, SQLContext, HiveContext\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fbf86c4aca92a1f60774ce2f57444891",
     "grade": true,
     "grade_id": "cell-17bdef576e075e06",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "55f1098b6633b820340c5bc748e3d5c9",
     "grade": false,
     "grade_id": "cell-08415507759b0533",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Introducció a dataframes estructurats i operacions sobre ells\n",
    "\n",
    "Com ja s'ha mencionat, en els següents exercicis utilitzarem dades de Twitter que vam recollir durant les eleccions generals a Espanya del 28 d'abril de 2019. Com veurem, els tweets tenen una estructura interna força complexa que hem simplificat una mica en aquesta pràctica.\n",
    "\n",
    "El primer que aprendrem és com importar aquest tipus de dades al nostre entorn. Un dels tipus d'arxius més comuns per guardar aquest format d'informació és [l'estructura JSON](https://en.wikipedia.org/wiki/JSON). Aquesta estructura permet guardar informació en un text pla de diferents objectes seguint una estructura de diccionari on cada camp té assignat una clau i un valor. L'estructura pot ser niada, és a dir, que una clau pot tenir com a valor una altra estructura de tipus diccionari.\n",
    "\n",
    "Spark SQL permet llegir dades de molts formats diferents. Se us demana que [llegiu el fitxer JSON](https://archive.apache.org/dist/spark/docs/2.4.0/sql-data-sources-json.html) de la ruta ```/aula_M2.858/data/tweets28a_sample.json```. Aquest arxiu conté una petita mostra, un 0.1% de la base de dades completa (en un següent apartat veurem com realitzar aquest mostreig). En aquesta ocasió no se us demana especificar l'estructura del dataframe ja que la funció de lectura la inferirà automàticament.\n",
    "\n",
    "**Exemple de lectura (Omplir amb el corresponent per a la lectura de l'arxiu json)**:\n",
    "\n",
    "\n",
    "```Python\n",
    "sqlContext = SQLContext(sc)\n",
    "tweets_sample = sqlContext.read.<FILL IN>\n",
    "\n",
    "print(\"Loaded dataset contains %d tweets\" % tweets_sample.count())\n",
    "```\n",
    "\n",
    "Per mostrar l'estructura del dataset que acabem de carregar, podeu obtenir la informació sobre com està estructurat el DataTable utilitzant el mètode ```printSchema()```. Heu de familiaritzar-vos amb aquesta estructura ja que serà la que utilitzarem durant els propers exercicis. Recordeu també que no tots els tweets tenen tots els camps, com per exemple la ubicació (camp ```place```). Quan això passa el camp passa a ser ```NULL```. Podeu veure més informació sobre aquest tipus de dades en [aquest enllaç](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object).\n",
    "\n",
    "Ara heu d'introduir l'exemple de lectura amb el `<FILL IN>` omplert segons correspongui per a la lectura de l'arxiu JSON. I, a continuació, mostrareu l'estructura del dataset utilitzant `printSchema()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f4a7c25d8bcc27c779d8631207cb32ee",
     "grade": true,
     "grade_id": "cell-cd35031d23b818d2",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b61c8666c39ef5b38268f8bbd1cb68e",
     "grade": true,
     "grade_id": "cell-65348d9b523338e5",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT USE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da28d5170a70b82715b3a2bc5f367ca7",
     "grade": false,
     "grade_id": "cell-819d752224637bc0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Consultes sobre dataframes complexos\n",
    "\n",
    "A continuació veurem com realitzar consultes sobre el dataset dels tweets. Utilitzarem [sentències *SQL*](https://www.w3schools.com/sql/default.asp) (com les utilitzades en la majoria de bases de dades relacionals).\n",
    "\n",
    "El primer que s'ha de fer és registrar el dataframe de tweets com una taula de SQL. Per a això utilitzarem [sqlContext.registerDataFrameAsTable()](https://archive.apache.org/dist/spark/docs/2.4.0/api/python/pyspark.sql.html#pyspark.sql.SQLContext.registerDataFrameAsTable). Per executar comandes sql només heu d'utilitzar el mètode sql() de l'objecte context, en aquest cas `sqlContext`.\n",
    "\n",
    "#### Consultes a través del pipeline\n",
    "Les taules de Spark SQL ofereixen un altre mecanisme per aplicar les transformacions i obtenir resultats similars als que s'obtindrien aplicant una consulta SQL. Per exemple, utilitzant el següent pipeline obtindrem el text de tots els tweets en espanyol:\n",
    "\n",
    "```\n",
    "tweets_sample.where(\"lang == 'es'\").select(\"text\")\n",
    "```\n",
    "\n",
    "Què és equivalent a la següent sentència SQL:\n",
    "\n",
    "```\n",
    "SELECT text\n",
    "FROM tweets_sample\n",
    "WHERE lang == 'es'\n",
    "```\n",
    "\n",
    "Podeu consultar l'[API de spark SQL](https://archive.apache.org/dist/spark/docs/2.4.0/api/python/pyspark.sql.html) per trobar més informació sobre com utilitzar les diferents transformacions en taules.\n",
    "\n",
    "### **Exercici 5**: Anàlisi de Tweets mitjançant DataFrames i consultes SQL (*2 punts*)\n",
    "\n",
    "Anteriorment ja has realitzat la lectura del conjunt `tweets28a_sample.json` en format JSON. Ara hauràs d'assegurar-te de registrar el DataFrame com una taula SQL anomenada `tweets_sample`.\n",
    "\n",
    "***Nota:*** A causa que és possible que executis aquestes línies de codi diverses vegades, prendrem la precaució d'executar la comanda SQL per eliminar taules abans que les creïs, ja que pot existir la possibilitat que ja existeixin.\n",
    "\n",
    "`sqlContext.sql(\"DROP TABLE IF EXISTS tweets_sample\")`\n",
    "\n",
    "A continuació, es demana crear una taula i registrar-la amb el nom ```users_agg``` amb [la informació agregada](https://www.w3schools.com/sql/sql_groupby.asp) dels usuaris que tinguin definit el seu idioma (```user.lang```) com a espanyol (```es```). En concret es demana que la taula contingui les següents columnes:\n",
    "- **screen_name:** nom de l'usuari\n",
    "- **friends_count:** nombre màxim (veure nota) de persones a les quals segueix\n",
    "- **tweets:** nombre de tweets realitzats\n",
    "- **followers_count:** nombre màxim (veure nota) de persones que segueixen l'usuari.\n",
    "\n",
    "L'ordre en el qual s'han de mostrar els registres és ordre descendent d'acord amb el nombre de tweets.\n",
    "\n",
    "***Nota:*** És important que tinguis en compte que el nom de *friends* i *followers* pot diferir al llarg de l'adquisició de dades. En aquest cas utilitzarem la funció d'agregació `MAX` sobre cadascun d'aquests camps per evitar segmentar l'usuari en diverses instàncies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "94b042131ca75243540d4dba151106e5",
     "grade": false,
     "grade_id": "cell-61484843695e0af4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ddb6d1ff9d282bf041c958a51409b251",
     "grade": true,
     "grade_id": "cell-ef7edc9cd8f50aaa",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "hidden"
    ]
   },
   "outputs": [],
   "source": [
    "# DO NOT USE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "81d70b6ad52f2c15ef4e8e4a7cd5673a",
     "grade": false,
     "grade_id": "cell-707f689f738619d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "A continuació, recorrerem al [JOIN de taules](https://www.w3schools.com/sql/sql_join.asp) per combinar la informació entre taules. Has de combinar la taula `users_agg` i la taula `tweets_sample` utilitzant un `INNER JOIN` per obtenir una nova taula amb el nom `retweeted` amb la següent informació:\n",
    "- ***screen_name:*** nom d'usuari\n",
    "- ***friends_count:*** nombre màxim de persones a les quals segueix\n",
    "- ***followers_count:*** nombre màxim de persones que segueixen l'usuari.\n",
    "- ***tweets:*** nombre de tweets realitzats per l'usuari.\n",
    "- ***retweeted:*** nombre de retweets obtinguts per l'usuari.\n",
    "- ***ratio_tweet_retweeted:*** ràtio de retweets per nombre de tweets publicats $\\frac{retweets}{tweets}$\n",
    "\n",
    "La taula resultant `retweeted` ha d'estar ordenada de manera descendent segons el valor de la columna `ratio_tweet_retweeted`.\n",
    "\n",
    "Per últim, utilitzant queries a través de pipeline, has de crear una taula `user_retweets` a partir de la taula `tweets_sample`, utilitzant transformacions que contingui dues columnes:\n",
    "- ***screen_name:*** nom d'usuari\n",
    "- ***retweeted:*** nombre de retweets\n",
    "\n",
    "Ordena la taula en ordre descendent utilitzant el valor de la columna ```retweeted```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eda20c4042b6abfcc721827bba89534c",
     "grade": false,
     "grade_id": "cell-d437d92649bff2c3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "520d74604bf7faa8b463da8b47307368",
     "grade": true,
     "grade_id": "cell-b54605adb4fc0173",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "hidden"
    ]
   },
   "outputs": [],
   "source": [
    "# DO NOT USE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a193ba4fb4adc2be863684c3e10491af",
     "grade": false,
     "grade_id": "cell-ee6926263623ddb2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Bases de dades HIVE i operacions complexes\n",
    "\n",
    "Fins ara hem estat treballant amb una petita mostra dels tweets generats (el 0.1%). En aquesta part de l'activitat veurem com treballar i tractar amb el dataset complet. Per això utilitzarem tant transformacions sobre taules com operacions sobre RDD quan sigui necessari.\n",
    "\n",
    "És important tenir en compte que moltes vegades les dades amb les quals treballem s'utilitzaran en diversos projectes. En lloc de manejar directament els arxius, és més eficient i organitzat recórrer a una base de dades per gestionar la informació. En l'ecosistema de Hadoop, una de les bases de dades més utilitzades és [Apache Hive](https://hive.apache.org/). No obstant això, és crucial entendre que Hive no és una base de dades convencional. En realitat, funciona com un metastore que mapatge arxius en el sistema de fitxers distribuït de Hadoop (HDFS).\n",
    "\n",
    "Això significa que Hive no emmagatzema les dades en el seu propi format de base de dades, sinó que actua com una interfície que permet als usuaris executar consultes SQL sobre les dades emmagatzemades en HDFS. Això proporciona una manera eficient d'accedir i manipular grans volums de dades distribuïdes sense necessitat de moure-les o convertir-les a un format tradicional de base de dades.\n",
    "\n",
    "La manera d'accedir a aquesta base de dades és creant un context Hive de manera molt similar a com declarem un context SQL. Primer declararem una variable ```hiveContext``` instanciant-la com un objecte de la classe ```HiveContext```. Acte seguit comprovarem quantes taules estan registrades en aquest context.\n",
    "\n",
    "**Esquema**\n",
    "```Python\n",
    "hiveContext = <FILL IN>\n",
    "hiveContext.tables().show()\n",
    "```\n",
    "\n",
    "Executa aquest esquema amb el FILL IN omplert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "349d58c49dfaf1f165dbc6a9192e1602",
     "grade": true,
     "grade_id": "cell-bab26dda42048abd",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dc8ab12a43f035538cadcb40a812ec1d",
     "grade": false,
     "grade_id": "cell-cc6dc65ad219a2f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Observa que ara mateix tenim diverses taules registrades en aquest context. Algunes d'elles no temporals i dues temporals, les que hem registrat prèviament. Per tant, sqlContext i hiveContext estan connectats (és la mateixa sessió).\n",
    "\n",
    "### Més enllà de les transformacions SQL\n",
    "\n",
    "Algunes vegades necessitarem obtenir resultats que precisen operacions que van més enllà del que podem aconseguir (còmodament) utilitzant el llenguatge SQL. En aquesta part de la pràctica veurem com passar d'una taula a un RDD, per fer operacions complexes, i després tornar a passar a una taula.\n",
    "\n",
    "Ara ve la part interessant. Una taula pot convertir-se en un RDD a través de l'atribut ```.rdd```. Aquest atribut guarda la informació de la taula en una llista on cada element és un [objecte del tipus ```Row```](https://archive.apache.org/dist/spark/docs/2.4.0/api/python/pyspark.sql.html#pyspark.sql.Row). Els objectes pertanyents a aquesta classe poden veure's com diccionaris on la informació de les diferents columnes queda reflectida en forma d'atribut. Per exemple, imagineu que tenim una taula amb dues columnes, nom i cognom, si utilitzem l'atribut ```.rdd``` d'aquesta taula obtindrem una llista amb objectes del tipus row on cada objecte té dos atributs: nom i cognom. Per accedir als atributs només heu d'utilitzar la sintaxi *punt* de Python, per exemple, ```row.nom``` o ```row.cognom```.\n",
    "\n",
    "### **Exercici 6**: Anàlisi de Tweets Geolocalitzats (*1.5 punts*)\n",
    "\n",
    "Donada la taula de tweets `tweets28a_sample25`, has de crear una variable `tweets` amb `hiveContext` utilitzant el mètode `table()`. Utilitzant una sentència SQL, es requereix extreure informació sobre els tweets que contenen dades geolocalitzades (és a dir, aquells on el camp `place` no és nul) i determinar quants tweets s'han generat des de cada lloc. Els resultats han de ser presentats en ordre descendent per la quantitat de tweets.\n",
    "\n",
    "**Esquema sentència sql**\n",
    "```Python\n",
    "tweets_place = hiveContext.sql(<FILL IN>)\n",
    "```\n",
    "A continuació, crea una taula anomenada `tweets_place` que contingui dues columnes:\n",
    "\n",
    "- ***name:*** nom del lloc des d'on s'ha generat el tweet.\n",
    "- ***tweets:*** nombre total de tweets realitzats en aquest lloc.\n",
    "\n",
    "Finalment, mostra els 10 llocs amb major nombre de tweets a la taula resultant.\n",
    "\n",
    "Addicionalment, crea una taula anomenada `tweets_geo` que contingui únicament els tweets que tenen informació de geolocalització, i assegura't que inclogui el nom del lloc. A partir d'aquesta taula, crea un objecte ```tweets_place_rdd``` que contingui una llista de tuples amb la informació ```(name, tweets)``` sobre el nom del lloc i el nombre de tweets generats des d'allà.\n",
    "\n",
    "Un cop generat aquest RDD, crearem una taula que anomenaràs també `tweets_place`. El primer pas és generar per cada tupla un objecte Row que contingui un atribut ```name``` i un atribut ```tweets```. Ara només heu d'aplicar el mètode ```toDF()``` per generar una taula. Ordeneu les files d'aquesta taula pel nombre de tweets en ordre descendent.\n",
    "\n",
    "L'exercici s'ha de realitzar combinant tant sentències SQL com RDD en Apache Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "22137856a6a8329e81b4df4837db9362",
     "grade": false,
     "grade_id": "cell-17e6c49377cef82f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Creació de la variable tweets amd hiveContext\n",
    "\n",
    "\n",
    "# Extreure informació sobre els tweets on el camp place no és null\n",
    "\n",
    "\n",
    "# Determinar quants tweets s'han generat des de cada lloc\n",
    "\n",
    "# Presentar els resultats en ordre descendent per la quantitat de tweets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df62d300ffd9be24e43f21aedb39a89d",
     "grade": true,
     "grade_id": "cell-2997ae4966dc4f47",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "hidden"
    ]
   },
   "outputs": [],
   "source": [
    "# DO NOT USE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cbeabfefff7977f41997451589ae214a",
     "grade": false,
     "grade_id": "cell-2e89c0fb2e623367",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Mostreig\n",
    "\n",
    "En moltes ocasions, abans de llançar processos costosos, és una pràctica habitual tractar amb un petit conjunt de les dades per investigar algunes propietats o simplement per depurar els nostres algoritmes, a aquesta tasca se la coneix com a mostreig. En aquesta part de la pràctica veurem els dos principals mètodes de mostreig i com utilitzar-los.\n",
    "\n",
    "### Nota:\n",
    "Per produir un gràfic de barres utilitzant [Pandas](https://pandas.pydata.org/) on es mostri la informació que acabeu de generar. Primer transformeu la taula a pandas utilitzant el mètode `toPandas()`. Ploteu la taula resultant utilitzant [la funcionalitat gràfica de pandas.](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.bar.html)\n",
    "\n",
    "### Homogeni\n",
    "\n",
    "El primer mostreig que veurem és [l'homogeni](https://en.wikipedia.org/wiki/Simple_random_sample). Aquest mostreig es basa en simplement escollir una fracció de la població seleccionant aleatòriament elements d'aquesta.\n",
    "\n",
    "Primer de tot realitzarem un mostreig homogeni de l'1% dels tweets generats en període electoral sense reemplaçament. Guardeu en una variable ```tweets_sample``` aquest mostreig utilitzant el mètode ```sample``` descrit a l'[API de pyspark SQL](https://archive.apache.org/dist/spark/docs/2.4.0/api/python/pyspark.sql.html). La llavor que utilitzareu per inicialitzar el generador aleatori és 42.\n",
    "\n",
    "**Esquema**\n",
    "```Python\n",
    "seed = 42\n",
    "fraction = 0.01\n",
    "\n",
    "tweets_sample = tweets.<FILL IN>\n",
    "\n",
    "print(\"Number of tweets sampled: {0}\".format(tweets_sample.count()))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercici 7**: Anàlisi del Patró d'Activitat Horària a Twitter (*1 punts*)\n",
    "A partir d'una mostra de l'1% dels tweets disponibles, es desitja analitzar el patró d'ús diari de Twitter, prestant especial atenció a l'activitat horària. L'objectiu és calcular i visualitzar la mitjana de tweets generats en cada hora del dia. Per a això s'ha de crear una taula ```tweets_timestamp``` amb la informació:\n",
    "- ***created_at***: timestamp de quan es va publicar el tweet.\n",
    "- ***hour***: a quina hora del dia correspon.\n",
    "- ***day***: Data en format MM-dd-YY\n",
    "\n",
    "La taula ha d'estar en ordre ascendent segons la columna `created_at`\n",
    "\n",
    "**Pista**: Per crear les columnes \"hour\" i \"day\" a la teva taula tweets_timestamp, pots utilitzar withColumn(). La funció ```hour``` et servirà per extreure l'hora del timestamp i la funció ```date_format``` et permetrà generar la data.\n",
    "\n",
    "A continuació, utilitza la mostra de tweets per extreure l'hora i data de publicació, i a partir d'aquesta informació, determina quants tweets es generen per hora, has de crear una taula `tweets_hour_day` a partir d'aquesta informació.\n",
    "\n",
    "Finalment, només ens queda fer una agregació per hora per aconseguir la mitjana de tweets per hora. Heu de generar una taula ```tweets_hour``` amb la informació:\n",
    "- ***hour:*** Hora\n",
    "- ***tweets:*** Mitjana de tweets realitzats\n",
    "\n",
    "Recordeu que estem treballant amb un sample de l'1% per tant heu de corregir la columna ```tweets``` perquè reflecteixi la mitjana que hauríem d'esperar en el conjunt complet de tweets. La taula ha d'estar ordenada en ordre ascendent d'hora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a412b274010d283eebb1b262ab4e49a",
     "grade": false,
     "grade_id": "cell-9e4ac72a18212c9f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da0955911ded10201a2997d1fb58c859",
     "grade": true,
     "grade_id": "cell-dbbc7b6886dfb6c4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "hidden"
    ]
   },
   "outputs": [],
   "source": [
    "# DO NOT USE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b75f84d86cdb6b1d65674490fcba75a",
     "grade": false,
     "grade_id": "cell-28db2ef4b5016901",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Estratificat\n",
    "\n",
    "En moltes ocasions el mostreig homogeni no és adequat ja que per la pròpia estructura de les dades determinats segments poden estar sobre-representades. Aquest és el cas que observem en els tweets on les grans àrees urbanes estan sobrerepresentades si ho comparem amb el volum de població. En aquesta activitat veurem com aplicar aquesta tècnica al dataset de tweets, per obtenir un mostreig que respecti la proporció de diputats per província.\n",
    "\n",
    "A Espanya, el procés electoral assigna un volum de diputats a cada província que depèn de la població i d'un percentatge mínim assignat per llei. En el context Hive que hem creat prèviament (```hiveContext```) podem trobar una taula (```province_28a```) que conté informació sobre les circumscripcions electorals. Carregueu aquesta taula en una variable amb nom ```province```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "746d9729322ecb2c4cca732de281fb70",
     "grade": true,
     "grade_id": "cell-ef29acbef76f9bcc",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "province.limit(20).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c5f0ec6109ce43c0d1f90eb77d180d5",
     "grade": false,
     "grade_id": "cell-7d381e80e8b40560",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "hidden"
    ]
   },
   "outputs": [],
   "source": [
    "assert province.count() == 52, \"Incorrect answer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e6441366f82adbe8097ed2bb93bd2d6d",
     "grade": false,
     "grade_id": "cell-12bff98437b3005c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Per fer un mostreig estratificat, primer hem de determinar la fracció que volem assignar a cada categoria. En aquest cas, volem una fracció que faci que la ràtio tweets per diputat sigui igual per a totes les capitals de província. Hem de tenir en compte que la precisió de la geolocalització a Twitter és normalment a nivell de ciutat. Per això, per evitar incrementar la complexitat de l'exercici, utilitzarem els tweets en capitals de província com a proxy dels tweets en tota la província.\n",
    "\n",
    "### **Exercici 8**: Anàlisi de la Relació entre Tweets i Diputats per Província (*0.75 punts*)\n",
    "\n",
    "El primer que heu de fer és crear una taula ```info_tweets_province``` que ha de contenir:\n",
    "- ***capital:*** nom de la capital de província.\n",
    "- ***tweets:*** nombre de tweets geolocalitzats en cada capital.\n",
    "- ***diputats:*** diputats assignats a la província.\n",
    "- ***ratio_tweets_diputat:*** nombre de tweets per diputat.\n",
    "\n",
    "Heu d'ordenar la llista per ```ratio_tweets_diputado``` en ordre ascendent.\n",
    "\n",
    "***Nota:*** Podeu realitzar aquest exercici de moltes maneres, probablement la més fàcil és utilitzar la taula ```tweets_place``` que heu generat en l'exercici 5. Recordeu com utilitzar el ```join()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d23d25dcb82e2bc7dffc12cd2c037f4",
     "grade": false,
     "grade_id": "cell-79efcec5c58604f2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# VARIABLES DONADES (Las farem servir després)\n",
    "output = info_tweets_province.first()\n",
    "maximum_ratio = floor(output.ratio_tweets_diputado * 100) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4043c385d0ec50ffd9db27e3480f0973",
     "grade": true,
     "grade_id": "cell-b3022ef230864c39",
     "locked": true,
     "points": 0.4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "hidden"
    ]
   },
   "outputs": [],
   "source": [
    "# DO NOT USE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1aeee8eabf55b7a266c016a18b9769d4",
     "grade": false,
     "grade_id": "cell-565f4ca847f1d4bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "A continuació, necessitem un diccionari amb el nom ```ratios``` on cada capital de província és una clau i el seu valor associat és la fracció de tweets que anem a mostrejar. En aquest cas, el que volem és que la ràtio de tweets per cada diputat sigui similar per a cada capital de província.\n",
    "\n",
    "Com que volem que el mostreig sigui el més gran possible i no volem que cap capital estigui infrarepresentada, la ràtio de tweets per diputat serà el valor més petit que podeu observar a la taula ```info_tweets_province```, que correspon a 11.66 tweets per diputat a Teruel. Teniu aquest valor guardat a la variable ```maximum_ratio```.\n",
    "\n",
    "*Nota:* El mètode ```collectAsMap()``` transforma un PairRDD en un diccionari.\n",
    "\n",
    "Finalment, genera una taula ```geo_tweets``` amb tots els tweets geolocalitzats. Ara ja estem en disposició de fer el mostreig estratificat per població. Per a això podeu utilitzar el mètode ```sampleBy()```. Utilitzeu 42 com a llavor del generador pseudoaleatori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df13bdefb79e493cb9bbed8f66a4f6a0",
     "grade": false,
     "grade_id": "cell-1106beacc9ee80b3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df5eb5707268f61e79d524aebb93e35e",
     "grade": true,
     "grade_id": "cell-3ddacba93fc16767",
     "locked": true,
     "points": 0.35,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "hidden"
    ]
   },
   "outputs": [],
   "source": [
    "# DO NOT USE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1cb449ff38cfe5303b148fdbdd7412d6",
     "grade": false,
     "grade_id": "cell-d8e5effe60498577",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Introducció a les dades relacionals\n",
    "\n",
    "El fet de treballar amb una base de dades que conté informació generada en una xarxa social ens permet introduir el concepte de dades relacionals. Podem definir dades relacionals com aquelles en què existeixen relacions entre les entitats que constitueixen la base de dades. Si aquestes relacions són binàries, relacions 1 a 1, podem representar les relacions com un graf compost per un conjunt de vèrtexs $\\mathcal{V}$ i un conjunt d'arestes $\\mathcal{E}$ que els relacionen.\n",
    "\n",
    "En el cas de grafs que emergeixen de manera orgànica, aquest tipus d'estructura va més enllà dels grafs regulars que segurament coneixeu. Aquest tipus d'estructures es coneixen com a [xarxes complexes](https://ca.wikipedia.org/wiki/Xarxa_complexa). L'estudi de l'estructura i dinàmiques d'aquest tipus de xarxes ha contribuït a importants resultats en camps tan dispars com la física, la sociologia, l'ecologia o la medicina.\n",
    "\n",
    "![complex_network](https://images.squarespace-cdn.com/content/5150aec6e4b0e340ec52710a/1364574727391-XVOFAB9P6GHKTDAH6QTA/lastfm_800_graph_white.png?content-type=image%2Fpng)\n",
    "\n",
    "En aquesta última part de la pràctica treballarem amb aquest tipus de dades. En concret modelarem una de les possibles relacions presents en el dataset, la xarxa de retweets.\n",
    "\n",
    "#### Construcció de l'edgelist\n",
    "\n",
    "El primer que se us demana és que genereu la xarxa. Hi ha diverses maneres de representar una xarxa complexa, per exemple, si estiguéssiu interessats a treballar-hi des del punt de vista teòric, la manera més habitual de representar-les és utilitzant una [matriu d'adjacència](https://ca.wikipedia.org/wiki/Matriu_d%27adjacència). En aquesta pràctica ens centrarem en l'aspecte computacional, una de les maneres més eficients (computacionalment parlant) de representar una xarxa és mitjançant la seva [*edge list*](https://en.wikipedia.org/wiki/Edge_list), una taula que especifica la relació a parelles entre les entitats.\n",
    "\n",
    "Les relacions poden ser bidireccionals o direccionals i tenir algun pes assignat o no (weighted or unweighted). En el cas que ens ocupa, estem parlant d'una xarxa dirigida, un usuari retuiteja a un altre, i podem pensar-la tenint en compte quantes vegades això ha passat.\n",
    "\n",
    "#### Centralitat de grau\n",
    "\n",
    "Un dels descriptors més comuns en l'anàlisi de xarxes és el grau. El grau quantifica quantes arestes estan connectades a cada vèrtex~s~. En el cas de xarxes dirigides com la que acabem de crear aquest descriptor està descompost en el:\n",
    "- **in degree**: quantes arestes apunten al node\n",
    "- **out degree**: quantes arestes surten del node\n",
    "\n",
    "Si fas un rànquing d'aquests valors obtindràs una mesura de centralitat, la [centralitat de grau](https://en.wikipedia.org/wiki/Centrality#Degree_centrality), de cadascun dels nodes.\n",
    "\n",
    "### **Exercici 9**: Anàlisi d'Interaccions de Retweets i Graus d'Usuari (*0.75 punts*)\n",
    "\n",
    "A partir d'una mostra homogènia de l'1% dels tweets, amb la llavor 42 per garantir la reproductibilitat, realitza una anàlisi de les interaccions de retweets entre usuaris a la xarxa social.\n",
    "\n",
    "**Esquema**\n",
    "```Python\n",
    "seed = 42\n",
    "sample = tweets.<FILL IN>\n",
    "```\n",
    "Crea una taula ```edgelist``` amb la següent informació:\n",
    "- ***src:*** usuari que retuiteja\n",
    "- ***dst:*** usuari que és retuitejat\n",
    "- ***weight:*** nombre de vegades que un usuari retuiteja a un altre.\n",
    "\n",
    "Filtra el resultat perquè contingui només les relacions amb un weight igual o superior a dos.\n",
    "\n",
    "A continuació, genera una taula `outDegree` amb la informació:\n",
    "- ***screen_name:*** nom de l'usuari.\n",
    "- ***outDegree:*** out degree del node.\n",
    "\n",
    "Ordena la taula per out degree en ordre descendent.\n",
    "\n",
    "Se us demana ara que genereu una taula `inDegree` amb la informació:\n",
    "- ***screen_name:*** nom de l'usuari.\n",
    "- ***inDegree:*** in degree del node.\n",
    "\n",
    "Ordena la taula per in degree en ordre descendent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05385651a3f9074c60f08ae4cd9a96b1",
     "grade": false,
     "grade_id": "cell-b61e1a6ae475959b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef646cc68f4dc5df45a6eeb6f917fd2e",
     "grade": true,
     "grade_id": "cell-672372274353fcf0",
     "locked": true,
     "points": 0.75,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "hidden"
    ]
   },
   "outputs": [],
   "source": [
    "# DO NOT USE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f5c54e67d0b1dc85cfa37ab20ff06ae0",
     "grade": false,
     "grade_id": "cell-49dfd94338cf09df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### **Exercici 10**: Distribució del Grau de Sortida en una Xarxa de Retweets (*0.75 punts*)\n",
    "\n",
    "A partir d'una mostra de l'1% dels tweets, amb una llavor de 42 per assegurar la reproductibilitat, realitza una anàlisi bàsica de la xarxa de retweets. El teu objectiu és calcular i mostrar la distribució de graus dels usuaris en la xarxa de retweets.\n",
    "\n",
    "Per a això, segueix aquests passos:\n",
    "\n",
    "- Crea una taula de Edgelist: Defineix una taula `edgelist` que contingui les relacions de retweet entre usuaris, on cada fila representa un retweet realitzat d'un usuari a un altre.\n",
    "\n",
    "- Calcula el Grau de Sortida (Out-Degree): Determina quants retweets ha realitzat cada usuari (és a dir, el nombre d'usuaris als quals cada usuari ha retuitejat). Anomena aquesta variable `outDegree`.\n",
    "\n",
    "- Obté la Distribució de Grau de Sortida: Crea una taula `outDegree_distribution` que mostri quants usuaris tenen un determinat nombre de retweets realitzats. Ordena els resultats pel grau de sortida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d21925c6aa54dde0a30455671053808d",
     "grade": false,
     "grade_id": "cell-05526ad59455d739",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5aa42adf43566830a8648da1a7872c0f",
     "grade": true,
     "grade_id": "cell-7e1c6a02603e3007",
     "locked": true,
     "points": 0.75,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "hidden"
    ]
   },
   "outputs": [],
   "source": [
    "# DO NOT USE THIS CELL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
